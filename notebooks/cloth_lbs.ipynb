{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d590122-e9db-4ee1-875e-cfe5e226f392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import scipy as sp\n",
    "import igl\n",
    "import robust_laplacian\n",
    "\n",
    "import os.path as osp\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import smplx\n",
    "import glob\n",
    "import cv2\n",
    "import os\n",
    "import pyrender\n",
    "import trimesh\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55e46c47-a7bd-4da6-a494-5a1db8a76c08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_orient': array([ 0.00492813,  1.6237236 , -0.0699005 ], dtype=float32),\n",
       " 'body_pose': array([-4.19760346e-02,  9.74555463e-02,  1.90463886e-01, -7.47566670e-02,\n",
       "        -7.21446872e-02, -1.57268777e-01, -4.56898585e-02,  4.43277182e-03,\n",
       "         5.37694916e-02, -6.97312132e-02,  8.66318271e-02,  9.14673135e-02,\n",
       "        -1.26157841e-02, -6.44140169e-02, -1.91337466e-02,  5.14160208e-02,\n",
       "        -1.75482202e-02,  8.12641811e-03,  1.33622453e-01,  5.47491647e-02,\n",
       "        -1.69454706e-05,  1.37154654e-01, -3.88579182e-02,  1.61871758e-05,\n",
       "         8.12471882e-02, -8.73514544e-03,  2.21590884e-02,  1.58502371e-05,\n",
       "         1.57070062e-05,  1.54597165e-05,  1.54723148e-05,  1.39889626e-05,\n",
       "        -1.51485538e-05, -1.13553563e-02, -4.63176444e-02, -6.14181906e-02,\n",
       "        -5.00713438e-02,  2.19184086e-01, -1.77930251e-01, -2.58259997e-02,\n",
       "        -1.98528439e-01,  1.84636593e-01,  7.81371593e-02, -1.03415944e-01,\n",
       "         8.63157436e-02, -8.68193135e-02,  5.43496907e-02, -8.56566191e-01,\n",
       "        -1.09648116e-01, -9.27179903e-02,  7.91208029e-01, -1.59979597e-01,\n",
       "        -2.75426865e-01, -1.75795659e-01, -2.29377076e-01,  2.50623375e-01,\n",
       "         1.83308139e-01, -1.88173577e-01,  1.04897760e-01,  2.87338167e-01,\n",
       "        -3.42139035e-01, -1.86785981e-01, -3.18695724e-01], dtype=float32),\n",
       " 'transl': array([-0.27039704,  1.654996  ,  0.06030658], dtype=float32),\n",
       " 'left_hand_pose': array([ 0.24533834,  0.25639087,  1.1378442 ,  1.3050905 , -0.61287695,\n",
       "         0.17628707,  0.594847  , -0.94713193, -0.28204727, -0.8395157 ,\n",
       "         0.7496384 , -0.93790734], dtype=float32),\n",
       " 'right_hand_pose': array([ 0.49076766, -0.12496671,  1.2996953 ,  2.257728  , -1.2435085 ,\n",
       "        -0.4797072 ,  0.87687254, -0.4344589 ,  0.35002387, -0.6775385 ,\n",
       "         0.57533854, -0.52049935], dtype=float32),\n",
       " 'jaw_pose': array([-0.017986  ,  0.03675405,  0.00671673], dtype=float32),\n",
       " 'leye_pose': array([0., 0., 0.], dtype=float32),\n",
       " 'reye_pose': array([0., 0., 0.], dtype=float32),\n",
       " 'expression': array([-1.6293507 ,  1.3311821 , -1.7076031 , -1.077231  , -0.9480654 ,\n",
       "        -1.2887822 , -0.5382567 ,  0.00653149,  1.9424397 ,  1.2784865 ],\n",
       "       dtype=float32),\n",
       " 'betas': array([ 0.02148489, -0.59162635,  0.477685  , -0.7797776 ,  0.1681296 ,\n",
       "        -1.3570437 , -0.10003285,  0.159951  , -0.5020329 , -0.56606394],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../00122/Outer/Take9/SMPLX/mesh-f00011_smplx.pkl', 'rb') as file:\n",
    "    smplx_data = pickle.load(file)\n",
    "smplx_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71136fb0-50ac-4d19-b7d3-8cca58269521",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['dynamic_lmk_bary_coords', 'hands_componentsl', 'ft', 'lmk_faces_idx', 'f', 'J_regressor', 'hands_componentsr', 'kintree_table', 'hands_coeffsr', 'joint2num', 'hands_meanl', 'lmk_bary_coords', 'weights', 'posedirs', 'dynamic_lmk_faces_idx', 'part2num', 'vt', 'hands_meanr', 'hands_coeffsl', 'v_template', 'shapedirs'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('/home/yeyiqi/Documents/repos/GaussianAvatar/assets/smpl_files/smplx/SMPLX_NEUTRAL.pkl', 'rb') as file:\n",
    "    model_data = pickle.load(file, encoding='latin1')\n",
    "model_data.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4054fe1a-9aa4-4806-8206-e47fb370e9f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_model_param = {\n",
    "    'betas': np.expand_dims(smplx_data['betas'],0),\n",
    "    'expression': np.expand_dims(smplx_data['expression'],0),\n",
    "    'transl': np.expand_dims(smplx_data['transl'],0),\n",
    "    'global_orient': np.expand_dims(smplx_data['global_orient'], 0),\n",
    "    'body_pose': np.expand_dims(smplx_data['body_pose'], 0),\n",
    "    'jaw_pose': np.expand_dims(smplx_data['jaw_pose'], 0),\n",
    "    'leye_pose': np.expand_dims(smplx_data['leye_pose'], 0),\n",
    "    'reye_pose': np.expand_dims(smplx_data['reye_pose'], 0),\n",
    "    'left_hand_pose': np.expand_dims(smplx_data['left_hand_pose'], 0),\n",
    "    'right_hand_pose': np.expand_dims(smplx_data['right_hand_pose'], 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f2ee2be-b554-40f4-adfe-9cac90530000",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_model_param_tensor = {\n",
    "    key: torch.tensor(body_model_param[key]) for key in body_model_param.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b539d4-33f6-4cd0-a12e-ed0ad8522cad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-1,  0,  0,  0,  1,  2,  3,  4,  5,  6,  7,  8,  9,  9,  9, 12, 13, 14,\n",
       "        16, 17, 18, 19, 15, 15, 15, 20, 25, 26, 20, 28, 29, 20, 31, 32, 20, 34,\n",
       "        35, 20, 37, 38, 21, 40, 41, 21, 43, 44, 21, 46, 47, 21, 49, 50, 21, 52,\n",
       "        53])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v_template = torch.from_numpy(model_data['v_template'])\n",
    "shapedirs = torch.from_numpy(model_data['shapedirs'])\n",
    "posedirs = torch.from_numpy(model_data['posedirs'])\n",
    "J_regressor = torch.from_numpy(model_data['J_regressor'])\n",
    "parents = torch.from_numpy(model_data['kintree_table'])\n",
    "weights = torch.from_numpy(model_data['weights'])\n",
    "parents = parents[0]\n",
    "parents[0] = -1\n",
    "parents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a4b74c2-203a-41e2-925c-49c323f18675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/yeyiqi/.conda/envs/MyFirst/lib/python3.10/site-packages/smplx/body_models.py:1009: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:278.)\n",
      "  dynamic_lmk_bary_coords = torch.tensor(\n"
     ]
    }
   ],
   "source": [
    "model_folder = '/home/yeyiqi/Documents/repos/GaussianAvatar/assets/smpl_files'\n",
    "model_type = 'smplx'\n",
    "\n",
    "kwargs = dict(\n",
    "        gender='neutral',\n",
    "        num_betas=10,\n",
    "        use_face_contour=True,\n",
    "        num_pca_comps=12,\n",
    "        use_pca=True,\n",
    "        batch_size=1,\n",
    "        ext = 'pkl'\n",
    ")\n",
    "model = smplx.create(\n",
    "    model_path = model_folder,\n",
    "    model_type = model_type,\n",
    "    **kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64cf4b9f-9db7-46e2-8ae9-f799467dd4af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 55, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "output = model(**body_model_param_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3bf409c8-fb31-4802-938d-6d667686e4c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55, 4, 4])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose1_tsm = output.transform_matrix\n",
    "pose1_tsm = pose1_tsm.squeeze()\n",
    "pose1_tsm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe468c9d-2c3a-4f0b-a215-26ce7c347600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'global_orient': array([-0.05113928,  1.0175937 , -0.0503974 ], dtype=float32),\n",
       " 'body_pose': array([ 1.33996606e-01,  2.34585330e-01,  2.02095106e-01, -2.09829733e-01,\n",
       "         1.08767666e-01, -5.03316559e-02,  1.23106748e-01, -3.99900436e-01,\n",
       "        -1.47038465e-02,  5.24092950e-02,  2.23365456e-01,  1.33410335e-01,\n",
       "         9.62239653e-02,  1.26511410e-01,  2.01036711e-03,  5.99068105e-02,\n",
       "        -3.24472427e-01,  2.22415533e-02,  1.26188725e-01,  3.26585501e-01,\n",
       "        -1.73083372e-05,  1.31123200e-01,  1.89871371e-01,  1.78726132e-05,\n",
       "        -4.11981717e-02, -2.93310344e-01,  3.28465551e-02,  1.53884012e-05,\n",
       "         1.64952598e-05,  1.53351175e-05,  1.45459526e-05,  1.51263275e-05,\n",
       "        -1.50468722e-05,  5.27108535e-02,  2.33393312e-01, -4.94126752e-02,\n",
       "        -1.57214791e-01, -8.92584324e-02,  3.24505717e-01, -2.01267511e-01,\n",
       "        -2.26869076e-01, -5.73507957e-02,  1.31839737e-02,  2.62128353e-01,\n",
       "        -8.07462484e-02, -4.62427773e-02, -3.90639484e-01, -1.04103014e-01,\n",
       "        -1.16273887e-01,  1.33252859e-01,  4.30595577e-01,  1.09309156e-03,\n",
       "        -1.17156851e+00,  1.09656000e+00, -1.54842138e-01,  1.28913713e+00,\n",
       "        -1.26261592e+00, -7.48612955e-02, -1.62803978e-01,  5.12766302e-01,\n",
       "        -1.93669498e-01,  1.17491886e-01, -4.52445835e-01], dtype=float32),\n",
       " 'transl': array([-0.26774278,  1.6572764 ,  0.11952823], dtype=float32),\n",
       " 'left_hand_pose': array([ 0.5627502 ,  0.92671436,  0.6372397 ,  0.3284181 ,  0.01208042,\n",
       "         1.1319271 ,  1.6151772 , -0.9205192 ,  1.0710651 , -0.27677596,\n",
       "         0.80028164,  0.60857683], dtype=float32),\n",
       " 'right_hand_pose': array([ 0.73364276,  0.48361328,  0.79817826,  0.67112345, -0.30440772,\n",
       "        -0.20643443,  1.7873285 , -0.98574805,  0.1268372 , -0.98243177,\n",
       "         1.2198294 , -0.06103888], dtype=float32),\n",
       " 'jaw_pose': array([0.09754179, 0.01433327, 0.00074884], dtype=float32),\n",
       " 'leye_pose': array([0., 0., 0.], dtype=float32),\n",
       " 'reye_pose': array([0., 0., 0.], dtype=float32),\n",
       " 'expression': array([ 1.7005887 , -0.6911128 , -2.6444762 , -1.3912305 , -1.3944199 ,\n",
       "        -1.3742838 , -2.5539217 ,  1.8114597 ,  0.9509855 ,  0.86595625],\n",
       "       dtype=float32),\n",
       " 'betas': array([ 0.02148489, -0.59162635,  0.477685  , -0.7797776 ,  0.1681296 ,\n",
       "        -1.3570437 , -0.10003285,  0.159951  , -0.5020329 , -0.56606394],\n",
       "       dtype=float32)}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('../00122/Outer/Take9/SMPLX/mesh-f00090_smplx.pkl', 'rb') as file:\n",
    "    smplx_data2 = pickle.load(file)\n",
    "smplx_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2433413e-311b-4426-a2e0-b21b620b90d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_model_param2 = {\n",
    "    'betas': np.expand_dims(smplx_data2['betas'],0),\n",
    "    'expression': np.expand_dims(smplx_data2['expression'],0),\n",
    "    'transl': np.expand_dims(smplx_data2['transl'],0),\n",
    "    'global_orient': np.expand_dims(smplx_data2['global_orient'], 0),\n",
    "    'body_pose': np.expand_dims(smplx_data2['body_pose'], 0),\n",
    "    'jaw_pose': np.expand_dims(smplx_data2['jaw_pose'], 0),\n",
    "    'leye_pose': np.expand_dims(smplx_data2['leye_pose'], 0),\n",
    "    'reye_pose': np.expand_dims(smplx_data2['reye_pose'], 0),\n",
    "    'left_hand_pose': np.expand_dims(smplx_data2['left_hand_pose'], 0),\n",
    "    'right_hand_pose': np.expand_dims(smplx_data2['right_hand_pose'], 0)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa52983f-0a2e-40f6-a27b-7286cd5a86fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "body_model_param_tensor2 = {\n",
    "    key: torch.tensor(body_model_param[key]) for key in body_model_param.keys()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c408a99-d08d-4b17-b68f-0f00e7fbf6f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 55, 3, 3])\n"
     ]
    }
   ],
   "source": [
    "output2 = model(**body_model_param_tensor2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4dcdd585-7055-4512-b2dc-3d02a70c4c5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55, 4, 4])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pose2_tsm = output2.transform_matrix\n",
    "pose2_tsm = pose2_tsm.squeeze()\n",
    "pose2_tsm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cecba17a-694f-4da9-839b-fd280569cc98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(PlyElement('vertex', (PlyProperty('x', 'float'), PlyProperty('y', 'float'), PlyProperty('z', 'float'), PlyProperty('red', 'uchar'), PlyProperty('green', 'uchar'), PlyProperty('blue', 'uchar'), PlyProperty('alpha', 'uchar'), PlyProperty('u', 'float'), PlyProperty('v', 'float')), count=15683, comments=[]),\n",
       " PlyElement('face', (PlyListProperty('vertex_indices', 'uchar', 'int'),), count=29318, comments=[]))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from plyfile import PlyData\n",
    "cloth = PlyData.read('./outer.ply')\n",
    "cloth.elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a267b60d-fbf8-43c7-a535-080881387d3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15683, 3])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloth_vertices_data = cloth['vertex'].data\n",
    "cloth_vertices = np.array([\n",
    "    (v['x'], v['y'], v['z'])\n",
    "    for v in cloth_vertices_data\n",
    "], dtype=np.float32)\n",
    "cloth_vertices_tensor = torch.from_numpy(cloth_vertices)\n",
    "cloth_vertices_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3bcd2a60-1432-41f5-9691-436050ed7c47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([29318, 3])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloth_face_data = cloth['face'].data\n",
    "cloth_faces = np.array([\n",
    "    list(f['vertex_indices'])\n",
    "    for f in cloth_face_data\n",
    "], dtype=np.int32)\n",
    "cloth_faces_tensor = torch.from_numpy(cloth_faces)\n",
    "cloth_faces_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0e5e055c-11cf-4c33-aa5c-a23924b9ae35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15683, 55])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloth_weights = np.load('outer_weights.npy')\n",
    "cloth_weights = torch.from_numpy(cloth_weights)\n",
    "cloth_weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "acf7000e-bec4-4c27-b1ab-aef9b5ee2c73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([55, 4, 4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R1 = pose1_tsm[:, :3, :3]\n",
    "t1 = pose1_tsm[:, :3, 3]\n",
    "R1_inv = torch.transpose(R1, 1, 2)\n",
    "t1_inv = -torch.bmm(R1_inv, t1.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "T1_inv = torch.eye(4).repeat(pose1_tsm.shape[0], 1, 1)\n",
    "T1_inv[:, :3, :3] = R1_inv\n",
    "T1_inv[:, :3, 3] = t1_inv\n",
    "\n",
    "T1_to_T2 = torch.bmm(pose2_tsm, T1_inv)\n",
    "T1_to_T2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eca8cd7c-6270-49aa-85e7-c99a9b42f85d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.3922,  1.2456, -0.3545,  1.0000],\n",
       "        [-0.3902,  1.2463, -0.3555,  1.0000],\n",
       "        [-0.3871,  1.2463, -0.3567,  1.0000],\n",
       "        ...,\n",
       "        [-0.1475,  1.1942,  0.1961,  1.0000],\n",
       "        [-0.4317,  1.6810, -0.0901,  1.0000],\n",
       "        [-0.2270,  1.7640,  0.2341,  1.0000]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloth_homogenous_verts = torch.cat([\n",
    "    cloth_vertices_tensor,\n",
    "    torch.ones(cloth_vertices_tensor.shape[0],1)\n",
    "], dim=1)\n",
    "cloth_homogenous_verts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "186a71f1-347d-4860-967e-2cfda2d3cce4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15683, 3])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_verts = torch.zeros_like(cloth_homogenous_verts)\n",
    "for j in range(T1_to_T2.shape[0]):\n",
    "    weight = cloth_weights[:, j].unsqueeze(-1)\n",
    "    verts_j = cloth_homogenous_verts @ T1_to_T2[j].T\n",
    "    transformed_verts += weight * verts_j\n",
    "transformed_verts = transformed_verts[:, :3]\n",
    "transformed_verts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e61ace46-bb54-44ba-b786-b2f8118da903",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.39217803,  1.2455803 , -0.35448405],\n",
       "       [-0.39018205,  1.2462603 , -0.35546705],\n",
       "       [-0.38706604,  1.2463005 , -0.3566731 ],\n",
       "       ...,\n",
       "       [-0.14750497,  1.1942499 ,  0.19611496],\n",
       "       [-0.43171102,  1.6810005 , -0.09013478],\n",
       "       [-0.22701296,  1.7639604 ,  0.23412089]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transformed_verts = transformed_verts.numpy()\n",
    "transformed_verts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aface224-7dc8-417e-a78e-d3d7903f75f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    4,     2,     1],\n",
       "       [    2,     4,     5],\n",
       "       [    2,     5,     6],\n",
       "       ...,\n",
       "       [  721,   634,   722],\n",
       "       [11703, 12022, 11708],\n",
       "       [11709, 11708, 12022]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cloth_faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "736b01c5-86ae-4308-bd74-15bc36c43872",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cloth_lbs.ply', 'w') as file:\n",
    "    file.write(f'ply\\n')\n",
    "    file.write(f\"format ascii 1.0\\n\")\n",
    "    file.write(f\"element vertex {len(transformed_verts)}\\n\")\n",
    "    file.write(f\"property float x\\n\")\n",
    "    file.write(f\"property float y\\n\")\n",
    "    file.write(f\"property float z\\n\")\n",
    "    file.write(f\"element face {len(cloth_faces)}\\n\")\n",
    "    file.write(f\"property list uchar int vertex_indices\\n\")\n",
    "    file.write(f\"end_header\\n\")\n",
    "    for i in range(len(transformed_verts)):\n",
    "        vertex = transformed_verts[i]\n",
    "        file.write(f\"{vertex[0]} {vertex[1]} {vertex[2]}\\n\")\n",
    "    for face in cloth_faces:\n",
    "        file.write(f\"3 {face[0]} {face[1]} {face[2]}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dabb8386-7b0c-4c53-a92d-0e1526abcf72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vertex has NaN: True\n"
     ]
    }
   ],
   "source": [
    "print(\"vertex has NaN:\", np.isnan(transformed_verts).any())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f2cd009-ac17-49e8-8f2d-c05a52e74528",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MyFirst",
   "language": "python",
   "name": "myfirst"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
